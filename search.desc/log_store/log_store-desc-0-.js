searchState.loadedDescShard("log_store", 0, "SNAFU context selector for the <code>Error::AddEntryLogBatch</code> …\nSNAFU context selector for the <code>Error::BatchProduce</code> variant\nSNAFU context selector for the <code>Error::BuildClient</code> variant\nSNAFU context selector for the <code>Error::BuildPartitionClient</code> …\nSNAFU context selector for the <code>Error::Cast</code> variant\nSNAFU context selector for the <code>Error::ConsumeRecord</code> variant\nSNAFU context selector for the <code>Error::CreateWriter</code> variant\nSNAFU context selector for the <code>Error::DecodeJson</code> variant\nSNAFU context selector for the <code>Error::DiscontinuousLogIndex</code>…\nSNAFU context selector for the <code>Error::EncodeJson</code> variant\nContains the error value\nSNAFU context selector for the <code>Error::FetchEntry</code> variant\nSNAFU context selector for the <code>Error::GetOffset</code> variant\nSNAFU context selector for the <code>Error::IllegalNamespace</code> …\nSNAFU context selector for the <code>Error::IllegalSequence</code> …\nSNAFU context selector for the <code>Error::IllegalState</code> variant\nSNAFU context selector for the <code>Error::InvalidProvider</code> …\nSNAFU context selector for the <code>Error::Io</code> variant\nSNAFU context selector for the …\nSNAFU context selector for the <code>Error::MissingKey</code> variant\nSNAFU context selector for the <code>Error::MissingValue</code> variant\nSNAFU context selector for the <code>Error::NoMaxValue</code> variant\nContains the success value\nSNAFU context selector for the …\nSNAFU context selector for the …\nSNAFU context selector for the <code>Error::ProduceRecord</code> variant\nSNAFU context selector for the <code>Error::RaftEngine</code> variant\nSNAFU context selector for the <code>Error::ReadIndex</code> variant\nSNAFU context selector for the <code>Error::ResolveKafkaEndpoint</code> …\nSNAFU context selector for the <code>Error::StartWalTask</code> variant\nSNAFU context selector for the <code>Error::StopWalTask</code> variant\nSNAFU context selector for the <code>Error::TlsConfig</code> variant\nSNAFU context selector for the <code>Error::WaitDumpIndex</code> variant\nSNAFU context selector for the …\nSNAFU context selector for the <code>Error::WriteIndex</code> variant\nConsume the selector and return the associated error\nConsume the selector and return the associated error\nConsume the selector and return the associated error\nConsume the selector and return the associated error\nConsume the selector and return the associated error\nConsume the selector and return the associated error\nConsume the selector and return the associated error\nConsume the selector and return the associated error\nConsume the selector and return the associated error\nConsume the selector and return the associated error\nConsume the selector and return the associated error\nConsume the selector and return the associated error\nConsume the selector and return a <code>Result</code> with the …\nConsume the selector and return a <code>Result</code> with the …\nConsume the selector and return a <code>Result</code> with the …\nConsume the selector and return a <code>Result</code> with the …\nConsume the selector and return a <code>Result</code> with the …\nConsume the selector and return a <code>Result</code> with the …\nConsume the selector and return a <code>Result</code> with the …\nConsume the selector and return a <code>Result</code> with the …\nConsume the selector and return a <code>Result</code> with the …\nConsume the selector and return a <code>Result</code> with the …\nConsume the selector and return a <code>Result</code> with the …\nConsume the selector and return a <code>Result</code> with the …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nKafka Entry implementation.\nThe <code>GlobalIndexCollector</code> struct is responsible for …\nKafka Namespace implementation.\nEntry payload.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nThe logical entry id.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nThe namespace used to identify and isolate log entries …\nTopic client.\nManages client construction and accesses.\nArc wrapper of ClientManager.\nReturns the argument unchanged.\nReturns the argument unchanged.\nGets the client associated with the topic. If the client …\nHigh watermark for each topic.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nUsed to initialize a new Client.\nTries to create a ClientManager.\nThe <code>Consumer</code> struct represents a Kafka consumer that …\nBuilder for <code>Consumer</code>.\nError type for ConsumerBuilder\nUninitialized field\nCustom validation error\nThe avg record size\nThe avg record size\nThe avg record size\nThe buffer of records.\nThe buffer of records.\nThe buffer of records.\nBuilds a new <code>Consumer</code>.\nThe client is used to fetch records from kafka topic.\nThe client is used to fetch records from kafka topic.\nThe client is used to fetch records from kafka topic.\nCreate an empty builder, with all fields set to <code>None</code> or …\nThe fetch future.\nThe fetch future.\nThe fetch future.\nFetch records.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nThe max batch size in a single fetch request.\nThe max batch size in a single fetch request.\nThe max batch size in a single fetch request.\nThe max wait milliseconds.\nThe max wait milliseconds.\nThe max wait milliseconds.\nCreates an empty <code>RecordsBuffer</code>\nTermination flag\nTermination flag\nTermination flag\nHighWatermarkManager is responsible for periodically …\nClient manager to send requests.\nReturns the argument unchanged.\nThe high watermark for each topic.\nCalls <code>U::from(self)</code>.\nStarts the high watermark manager as a background task\nAttempts to update the high watermark for all registered …\nInterval to update high watermark.\nThe <code>GlobalIndexCollector</code> struct is responsible for …\nThe <code>IndexCollector</code> trait defines the operations for …\nThe <code>NoopCollector</code> struct implements the <code>IndexCollector</code> …\nThe <code>ProviderLevelIndexCollector</code> struct is responsible for …\nThe <code>RegionIndexes</code> struct maintains indexes for a …\nAppends an <code>EntryId</code> for a specific region.\nDumps the index.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nConstructs a <code>GlobalIndexCollector</code>.\nCreates a new <code>ProviderLevelIndexCollector</code> for a specified …\nRetrieve <code>EntryId</code>s for a specified <code>region_id</code> in <code>datanode_id</code> …\nThe background task performs two main operations:\nSets the latest <code>EntryId</code>.\nTruncates the index for a specific region up to a given …\nTruncates the index for a specific region up to a given …\n<code>DatanodeWalIndexes</code> structure holds the WAL indexes for a …\nRepresents the delta-encoded version of region indexes for …\n<code>JsonIndexEncoder</code> encodes the <code>RegionIndexes</code>s into JSON …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nRetrieves the last index.\nRetrieves the delta encoded region indexes for a given …\nRetrieves the original (decoded) index values for a given …\nRepresents an iterator over multiple region WAL indexes.\nAn iterator over WAL (Write-Ahead Log) entries index for a …\nRepresents a range [next_entry_id, end_entry_id) of WAL …\nRepresents an index of Write-Ahead Log entries for a …\nBuilds <code>RegionWalIndexIterator</code>.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nReturns next batch hint.\nA log store backed by Kafka.\nAppends a batch of entries and returns a response …\nThe manager of topic clients.\nThe consumer wait timeout.\nCreates a new <code>Namespace</code> from the given ref.\nDeletes an existing <code>Namespace</code> specified by the given ref.\nCreates an Entry.\nReturns the argument unchanged.\nReturns the highest entry id of the specified topic in …\nHigh watermark for all topics.\nCalls <code>U::from(self)</code>.\nLists all existing namespaces.\nThe max size of a batch.\nMarks all entries with ids <code>&lt;=entry_id</code> of the given …\nIgnore missing entries during read WAL.\nCreates a new <code>EntryStream</code> to asynchronously generates <code>Entry</code>…\nStops components of the logstore.\nTries to create a Kafka log store.\n<code>OrderedBatchProducer</code> attempts to aggregate multiple …\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nConstructs a new <code>OrderedBatchProducer</code>.\nWrites <code>data</code> to the <code>OrderedBatchProducer</code>.\nSends an WorkerRequest::UpdateHighWatermark request to the …\nConvert a sequence of <code>EntryId</code>s into size ranges.\nMerge all ranges smaller than the <code>window_size</code>.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nMerges ranges.\nCalculates the size of the next merged range.\nThe estimated size in bytes of a serialized RecordMeta. A …\nThe record contains the first part of an entry’s data.\nThe record is self-contained, i.e. an entry’s data is …\nThe record contains the last part of an entry’s data.\nThe record contains one of the middle parts of an entry’…\nThe minimal storage unit in the Kafka log store.\nThe metadata of a record.\nThe type of a record.\nThe current version of Record.\nThe payload of the record.\nThe id of the entry the record associated with.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nFor type of Entry::Naive Entry:\nThe metadata of the record.\nThe namespace of the entry the record associated with.\nConstructs entries from <code>buffered_records</code>\nThe type of the record.\nThe version of the record. Used for backward compatibility.\nReceives the committed offsets when data has been …\nAggregates records into batches, ensuring that the size of …\nThe <code>ProducerClient</code>.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nHigh watermark for all topics.\nCollecting ids of WAL entries.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nMax bytes size for a single flush.\nReceiver of ProduceRequest.\nMax batch size for a worker to handle requests.\nUpdates the high watermark for the topic.\nWaits for the data has been committed to Kafka. Returns …\nLogstore label.\nCounter of bytes of the append_batch operation on the …\nTimer of the append_batch operation on the kafka logstore.\nCounter of bytes of the read operation on the kafka …\nTimer of the append_batch operation on the kafka logstore. …\nCounters of bytes of each operation on a logstore.\nTimer of operations on a logstore.\nCounter of bytes of the append_batch operation on the …\nTimer of the append_batch operation on the raft-engine …\nCounter of bytes of the read operation on the raft-engine …\nTimer of the append_batch operation on the raft-engine …\nOperation type label.\nKafka partition label.\nKafka topic label.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nRaftEngine based KvBackend implementation.\nKvBackend implementation based on raft_engine::Engine.\nCompress a log batch if its size exceeds this value. …\nDeprecated. Incrementally sync log files after specified …\nAcceleration factor for LZ4 compression. It can be fine …\nMain directory to store log files. Will create on startup …\nWhether to recycle stale log files. If <code>true</code>, logically …\nVersion of the log file.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nMaximum memory bytes allowed for the in-memory index. …\nWhether to prepare log files for recycling when start. If …\nMaximum capacity for preparing log files for recycling …\nPurge rewrite log queue if its garbage ratio exceeds this …\nPurge rewrite log queue if its size exceeds this value.\nPurge append log queue if its size exceeds this value.\nHow to deal with file corruption during recovery.\nMinimum I/O size for reading log files during recovery.\nThe number of threads used to scan and recovery log files.\nAuxiliary directory to store log files. Will create on …\nTarget file size for rotating log files.\nRaftEngine based KvBackend implementation.\nAppends a batch of entries to logstore. <code>RaftEngineLogStore</code> …\nConverts entries to <code>LogBatch</code> and checks if entry ids are …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCreate a stream of entries from logstore in the given …\nGenerated file from <code>logstore.proto</code>\nGenerated files are compatible only with the same version …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCreate a KafkaLogStore.\nCreate a write log for the provided path, used for test.")