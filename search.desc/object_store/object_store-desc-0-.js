searchState.loadedDescShard("object_store", 0, "Underlying trait of all backends for implementers.\nThe given path already exists thus we failed to the …\nBlockingDeleter is the associated deleter returned …\nBlockingLister is the associated lister returned …\nBlockingReader is the associated reader returned …\nBlockingWriter is the associated writer returned …\nBuffer is a wrapper of contiguous <code>Bytes</code> and non-contiguous …\nThe condition of this operation is not match.\nAssociated configuration for this builder.\nThe config for backend is invalid.\nDIR means the path can be listed.\nDeleter is the associated deleter returned in <code>delete</code> …\nEntry returned by <code>Lister</code> or <code>BlockingLister</code> to represent a …\nEntryMode represents the mode.\nContains the error value\nError is the error struct returned by all opendal …\nErrorKind is all kinds of Error of opendal.\nFILE means the path has data to read.\nFuturesAsyncReader is the adapter of <code>AsyncRead</code>, …\nFuturesIoAsyncWriter is the adapter of <code>AsyncWrite</code> for …\nHttpClient that used across opendal.\nThe given path is a directory.\nThe given file paths are same.\nLister is designed to list entries at given path in an …\nLister is the associated lister returned in <code>list</code> operation.\nThe given path is not a directory.\nThe given path is not found.\nThe default object cache directory name.\nThe <code>Operator</code> serves as the entry point for all public …\nBuilder is used to set up underlying services.\nContains the success value\nThe given path doesn’t have enough permission for this …\nThe range of the content is not satisfied.\nRequests that sent to this path is over the limit, please …\nReader is designed to read data from given path in an …\nReader is the associated reader returned in <code>read</code> operation.\nResult that is a wrapper of <code>Result&lt;T, opendal::Error&gt;</code>\nAssociated scheme for this builder. It indicates what …\nOpenDAL don’t know what happened here, and no actions …\nUnknown means we don’t know what we can do on this path.\nUnderlying service doesn’t support this operation.\nWriter is designed to write data into given path in an …\nWriter is the associated writer returned in <code>write</code> …\nAbort the writer and clean up all written data.\nCreate a new blocking operator.\nInvoke the <code>blocking_copy</code> operation on the specified <code>from</code> …\nInvoke the <code>blocking_create</code> operation on the specified path.\nInvoke the <code>blocking_delete</code> operation on the specified path.\nInvoke the <code>blocking_list</code> operation on the specified path.\nInvoke the <code>blocking_read</code> operation on the specified path.\nInvoke the <code>blocking_rename</code> operation on the specified <code>from</code> …\nInvoke the <code>blocking_stat</code> operation on the specified path.\nInvoke the <code>blocking_write</code> operation on the specified path.\nConsume the accessor builder to build a service.\nBuild a new http client in async context.\nCheck if this operator can work correctly.\nClose the writer and make sure all data have been …\nInvoke the <code>copy</code> operation on the specified <code>from</code> path and <code>to</code>…\nCopy a file from <code>from</code> to <code>to</code>.\nNumber of <code>Bytes</code> in <code>Buffer</code>.\nInvoke the <code>create</code> operation on the specified path\nCreate a dir at given path.\nGet current <code>Bytes</code>.\nGet the default executor.\nInvoke the <code>delete</code> operation on the specified path.\nDelete the given path.\nDelete an infallible iterator of paths.\nDelete an infallible stream of paths.\nDelete a fallible iterator of paths.\nDelete an fallible stream of paths.\nDelete the given path with extra options.\nCreate a <code>Deleter</code> to continuously remove content from …\nCheck if this path exists or not.\nFetch specific ranges from reader.\nFetch a request in async way.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCreate a new operator from given config.\nConvert inner accessor into operator.\nCreate a new operator from given iterator in static …\nCreate a new operator from given map.\nInvoke the <code>info</code> operation to get metadata of accessor.\nGet information of underlying accessor.\nFetch the internal accessor.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nConvert writer into <code>FuturesBytesSink</code> which implements …\nConvert reader into <code>FuturesBytesStream</code> which implements …\nConvert reader into <code>FuturesAsyncReader</code> which implements …\nConvert writer into <code>FuturesAsyncWriter</code> which implements …\nConvert operator into inner accessor.\nConsume this entry to get its path and metadata.\nConvert self into static str.\nCheck if this mode is DIR.\nCheck if buffer is empty.\nCheck if this path exists or not.\nCheck if this mode is FILE.\nCheck if this error is temporary.\nReturn error’s kind.\nCreate a new layer with dynamic dispatch.\nGet the length of the buffer.\nGet current operator’s limit. Limit is usually the …\nInvoke the <code>list</code> operation on the specified path.\nList entries that starts with given <code>path</code> in parent dir.\nList entries that starts with given <code>path</code> in parent dir …\nList entries that starts with given <code>path</code> in parent dir.\nList entries that starts with given <code>path</code> in parent dir …\nOperate on error with map.\nFetch metadata of this entry.\nobject-store metrics\nName of entry. Name is the last segment of path.\nCreate a new Error with error kind and message.\nCreate a new empty buffer.\nCreate a new operator with input builder.\nCreate a new http client in async context.\nPath of entry. Path is relative to operator’s root.\nInvoke the <code>presign</code> operation on the specified path.\nPresign an operation for read.\nPresign an operation for read with extra options.\nPresign an operation for stat(head).\nPresign an operation for stat(head).\nPresign an operation for write.\nPresign an operation for write with extra options.\nInvoke the <code>read</code> operation on the specified path, returns a …\nRead give range from reader into <code>Buffer</code>.\nRead the whole path into a bytes.\nRead all data from reader into given <code>BufMut</code>.\nRead the whole path into a bytes with extra options.\nCreate a new reader which can read the whole path.\nCreate a new reader with extra options\nNotes\nRemove the path and all nested dirs and files recursively.\nremove will remove files via the given paths.\nInvoke the <code>rename</code> operation on the specified <code>from</code> path and …\nRename a file from <code>from</code> to <code>to</code>.\nSend a request in async way.\nServices will provide builders to build underlying …\nSet permanent status for error.\nSet persistent status for error.\nSet source for error.\nSet temporary status for error.\nReturns a slice of self for the provided range.\nInvoke the <code>stat</code> operation on the specified path.\nGet given path’s metadata.\nGet given path’s metadata with extra options.\nCombine all bytes together into one single <code>Bytes</code>.\nConvert buffer into a slice of <code>IoSlice</code> for vectored write.\nCombine all bytes together into one single <code>Vec&lt;u8&gt;</code>.\nShortens the buffer, keeping the first <code>len</code> bytes and …\nCreate a new operator via given scheme and iterator of …\nCreate a new operator from given scheme and map.\nConstruct <code>Self</code> with given <code>reqwest::Client</code>\nAdd more context in error.\nSpecify the default executor.\nSpecify the batch limit.\nUpdate error’s operation.\nWrite <code>Buffer</code> into writer.\nInvoke the <code>write</code> operation on the specified path, returns a\nWrite bytes into path.\nWrite <code>bytes::Buf</code> into inner writer.\nWrite data with extra options.\nCreate a writer for streaming data to the given path.\nCreate a writer for streaming data to the given path with …\nAdd an extra capability check layer for every operation\nAdd concurrent request limit.\nAdd an immutable in-memory index for underlying storage …\nLoggingInterceptor is used to intercept the log.\nAdd log for every operation.\nAn opendal layer with local LRU file cache supporting.\nAdd prometheus for every operation.\n<code>PrometheusLayerBuilder</code> is a config builder to build a …\nRetryInterceptor is used to intercept while retry happened.\nAdd retry for temporary failed operations.\nAdd timeout for every operation to avoid slow or …\nAdd tracing for every operation.\nThis logical tries to extract parent path from the object …\nCreate a <code>PrometheusLayerBuilder</code> to set the configuration …\nInsert keys from iter.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nInsert a key into index.\nEverytime RetryLayer is retrying, this function will be …\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nEverytime there is a log, this function will be called.\nCreate a new retry layer.\nCreate a new ConcurrentLimitLayer will specify permits\nCreate the layer with specific logging interceptor.\nCreate a new <code>TimeoutLayer</code> with default settings.\nOpenDAL Observability Layer\nSet buckets for <code>operation_bytes</code> histogram.\nSet buckets for <code>operation_duration_seconds</code> histogram.\nSet the level of path label.\nRegister the metrics into the given registry and return a …\nRegister the metrics into the default registry and return …\nSet factor of current backoff.\nSet io timeout for TimeoutLayer with given value.\nSet jitter of current backoff.\nSet max_delay of current backoff.\nSet max_times of current backoff.\nSet min_delay of current backoff.\nSet the retry interceptor as new notify.\nSet speed for TimeoutLayer with given value.\nSet timeout for TimeoutLayer with given value.\nAn opendal layer with local LRU file cache supporting.\nReturns true when the local cache contains the specific …\nCreate a <code>LruCacheLayer</code> with local file cache and capacity …\nReturns the read cache statistics info …\nRecovers cache\nSubdirectory of cached files for read.\nLocal read cache for files in object storage\nCache value for read file\nReturns the cache’s entry count and total approximate …\nReturns true when the path of the file can be cached.\nReturns true when the read cache contains the specific …\nLocal file cache backend\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nInvalidate all cache items belong to the specific path.\nLocal memory cache to track local cache files\nCreate a <code>ReadCache</code> with capacity in bytes.\nGenerate a unique cache key for the read path and range.\nRead from a specific path using the OpRead operation. It …\nRead the file from remote storage. If success, write the …\nRecover existing cache items from <code>file_cache</code> to <code>mem_cache</code>. …\nThe metric label for the error kind.\nThe metric label for the namespace like bucket name in s3.\nThe metric label for the operation like read, write, list.\nThe metric label for the path used by request.\nThe metric label for the root path.\nThe metric label for the scheme like s3, fs, cos.\nThe metric metadata for the operation bytes.\nThe metric metadata for the operation duration in seconds.\nThe metric metadata for the operation errors total.\nThe metric metadata which contains the metric name and …\nThe metrics accessor for opendal.\nThe interceptor for metrics.\nThe metrics layer for opendal.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the metric help.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nReturns the metric name.\nReturns the metric name with a given prefix.\nCreate a new metrics layer.\nObserve the operation bytes happened in IO like read and …\nObserve the operation duration in seconds.\nObserve the operation errors total.\nReturn the path label value according to the given <code>path</code> …\nThis logical tries to extract parent path from the object …\nManages multiple object stores so that users can configure …\nAdds an object store to the manager.\nReturns the default object storage\nFinds an object store corresponding to the name.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCreates a new manager from the object store used as a …\nCache size in bytes\nCache entry number\nCache hit counter, no matter what the cache result is.\nCache miss counter\nObject store read error counter\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nConfig for Aliyun Drive services support.\nConfig for alluxio services support.\nConfig for Atomicserver services support\nCapabilities\nAzure Storage Blob services support.\nAzure Data Lake Storage Gen2 Support.\nAzure File services support.\nConfig for backblaze b2 services support.\ncacache service support.\nConfig for Chainsafe services support.\nCloudflare KV Service Support.\ncompio-based file system support.\nTencent-Cloud COS services support.\nConfig for Cloudflare D1 backend support.\ndashmap backend support.\nDbfs’s REST API support.\nConfig for Dropbox backend support.\nConfig for Etcd services support.\nfoundationdb service support. Config for FoundationDB.\nPOSIX file system support.\nconfig for file system\nConfig for Ftp services support.\nGoogle Cloud Storage services support.\nGoogle Cloud Storage services support.\nGoogleDrive configuration.\nConfig for GitHub Action Cache Services support.\nConfig for GitHub services support.\nConfig for Grid file system support.\nHadoop Distributed File System (HDFS™) support.\nConfig for HdfsNative services support.\nHTTP Read-only service support like Nginx and Caddy.\nConfig for Http service support.\nConfiguration for Huggingface service support.\nConfig for icloud services support.\nConfig for IPFS file system support.\nConfig for IPFS MFS support.\nConfig for Koofr services support.\nConfiguration for Lakefs service support.\nConfig for MemCached services support\nIn memory service support. (BTreeMap Based)\nConfig for memory.\nConfig for mini-moka support.\nConfig for Moka services support.\nConfig for Mongodb service support.\nConfig for monoiofs services support.\nConfig for Mysql services support.\nConfig for Mysql services support.\nConfig for Huawei-Cloud Object Storage Service (OBS) …\nConfig for OneDrive backend support.\nAliyun Object Storage Service (OSS) support\nConfig for Aliyun Object Storage Service (OSS) support.\nConfig for Pcloud services support.\nConfig for persy service support.\nConfig for PostgreSQL services support.\nConfig for redb service support.\nConfig for Redis services support.\nConfig for Rocksdb Service.\nAws S3 and compatible services (including minio, …\nConfig for Aws S3 and compatible services (including …\nConfig for seafile services support.\nConfig for Sftp Service support.\nConfig for Sled services support.\nConfig for Sqlite support.\nConfig for supabase service support.\nConfig for Surrealdb services support.\nConfig for OpenStack Swift support.\nConfig for Tikv services support.\nConfig for upyun services support.\nConfig for Vercel Cache support.\nConfig for VercelBlob services support.\nConfig for WebDAV backend support.\nConfig for WebHDFS support.\nConfig for YandexDisk services support.\nSet access_key_id of this backend.\nSet access_key_id of this backend.\nAccess key id for obs.\nAccess key id for oss.\naccess_key_id of this backend.\nSet access_key_secret of this backend.\nAccess key secret for oss.\nThe access_token of this backend.\naccess token for dropbox.\nAccess token for gdrive.\nbearer access token for OneDrive\nThe access token for Vercel.\nyandex disk oauth access_token.\nThe account ID used to authenticate with CloudFlare. Used …\nSet the account id of cloudflare api.\nSet account_key of this backend.\nThe account key of Azblob service backend.\nAccount key of this backend.\nThe account key for azfile.\nSet account_name of this backend.\nThe account name of Azblob service backend.\nAccount name of this backend.\nThe account name for azfile.\nAllow anonymous requests.\nAllow anonymous will allow opendal to send request without …\nAllow anonymous will allow opendal to send request without …\nAllow opendal to send requests without signing when …\nAllow anonymous for oss.\nAllow anonymous will allow opendal to send request without …\napi_key of this backend.\napple_id of this backend.\napplicationKey of this backend.\nkeyID of this backend.\nSet temp dir for atomic write.\ntmp dir for atomic write\natomic_write_dir of this backend\natomic_write_dir of this backend\nSet maximum batch operations of this backend.\nSet maximum batch operations of this backend.\nSet maximum batch operations of this backend.\nThe maximum batch operations of Azblob service backend.\nThe size of max batch operations.\nSet maximum batch operations of this backend.\nName of the branch or a commit ID. Default is main.\nset the container’s name\nSet bucket name of this backend.\nSet bucket name of this backend.\nbucket of this backend.\nBucket of this backend.\nbucket name\nThe bucket name of the MongoDB GridFs service to …\nBucket for obs.\nBucket for oss.\nbucket name of this backend.\nThe bucket for supabase service.\nbucket address of this backend.\nbucket id of this backend.\nbucket_id of this backend.\ncertificate authority file path\ncertificate authority file path\ncert path\ncert path\nSet checksum algorithm of this backend. This is necessary …\nChecksum Algorithm to use when sending checksums in HTTP …\nThe chunk size of the MongoDB GridFs service used to break …\nThe client_id of this backend.\nclient_id for dropbox.\nClient id for gdrive.\nThe client_secret of this backend.\nclient_secret for dropbox.\nClient secret for gdrive.\nnetwork address of the Redis cluster service. Can be “…\ncollection of this backend\nconfig_path for the backend.\nThe connection string of the MongoDB service.\nconnection string of this backend\nThis connection string is used to connect to the mysql …\nThe URL should be with a scheme of either <code>postgres://</code> or …\nSet the connection_string of the sqlite service.\nThe connection string for surrealdb.\nSet container name of this backend.\nThe container name of Azblob service backend.\nThe container for Swift.\nset the base64 hashed credentials string used for OAuth2 …\nCredentials string for GCS service OAuth2 authentication.\nset the local path to credentials file which is used for …\nLocal path to credentials file for GCS service OAuth2 …\nAdding a customized credential load for service.\nSpecify the customized token loader used by this service.\nThe database name of the MongoDB GridFs service to …\ndatabase of this backend\nThe database for surrealdb.\nSet the database id of cloudflare api.\nThat path to the cacache data directory.\npath to the redb data directory.\nThe path to the rocksdb data directory.\nThat path to the sled data directory.\nThat path to the persy data file. The directory in the …\nthe number of DBs redis can take is unlimited\nSet the default storage class for GCS.\nSet default storage_class for this backend.\nThe default storage class used by gcs.\ndefault storage_class for this backend.\nThe default ttl for put operations.\nThe default ttl for put operations.\nDelegation token for webhdfs.\nSet maximum delete operations of this backend.\nSet maximum delete operations of this backend.\nThe size of max delete operations.\nSet the maximum delete size of this backend.\nDetect region of S3 bucket.\nDisable loading configuration from the environment.\nDisable config load so that opendal will not load config …\nDisable config load so that opendal will not load config …\nDisable loading configuration from the environment.\nDisable config load so that opendal will not load config …\nWebDAV Service doesn’t support copy.\nDisable load credential from ec2 metadata.\nDisable load credential from ec2 metadata.\nDisable batch listing\nDisable stat with override so that opendal will not send …\nDisable stat with override so that opendal will not send …\nDisable attempting to load credentials from the GCE …\nDisable attempting to load credentials from the GCE …\nDisable write with if match so that opendal will not send …\nDisable write with if match so that opendal will not send …\nThe drive_type of this backend.\nds_web_auth_token must be set in Session\nKoofr email.\nenable the append capacity\nenable the append capacity\nenable_copy of this backend\nSet bucket versioning status for this backend\nSet bucket versioning status for this backend\nis bucket versioning enabled for this bucket\nis bucket versioning enabled for this bucket\nis bucket versioning enabled for this bucket\nEnable virtual host style so that opendal will send API …\nEnable virtual host style so that opendal will send API …\nSet encryption_algorithm of this backend.\nThe encryption algorithm of Azblob service backend.\nSet encryption_key of this backend.\nThe encryption key of Azblob service backend.\nSet encryption_key_sha256 of this backend.\nThe encryption key sha256 of Azblob service backend.\nSet endpoint of this backend\nset the endpoint GCS service uses\nSet endpoint for http backend.\nSet endpoint of this backend.\nSet endpoint of this backend.\nendpoint of this backend.\nendpoint of this backend\nThe endpoint of Azblob service backend.\nEndpoint of this backend.\nThe endpoint for azfile.\nEndpoint of this backend.\nThe endpoint for dbfs.\nendpoint of this backend\nendpoint URI of GCS service, default is …\nThe endpoint for ghac service.\nendpoint of this backend\nIPFS gateway endpoint.\nEndpoint for ipfs.\nKoofr endpoint.\nBase url.\nnetwork address of the memcached service.\nEndpoint for obs.\nEndpoint for oss.\npCloud  endpoint address.\nnetwork address of the Redis service. Can be “…\nendpoint of this backend.\nendpoint address of this backend.\nendpoint of this backend\nThe endpoint for supabase service.\nThe endpoint for Swift.\nendpoint of this backend\nEndpoint for webhdfs.\nnetwork address of the Etcd services. If use https, must …\nnetwork address of the TiKV service.\nSet external_id for this backend.\nexternal_id for this backend.\nFilesystem name of this backend.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nfrom_connection_string will make a builder from connection …\nThe host addr of nebulagraph’s graphd server\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nThat name of the persy index.\nwhether using insecure connection to TiKV\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nenable the china origin China region <code>origin</code> Header needs …\nkerberos_ticket_cache_path of this backend\nkey of this backend\nThe key for supabase service.\nSet the key field of D1 Database.\nkey field of this backend\nThe key field name for mysql.\nThe key field name of the NebulaGraph service to …\nthe key field of postgresql\nSet the key field name of the sqlite service to read/write.\nThe key field for surrealdb.\nkey path\nkey path\nknown_hosts_strategy of this backend\nSets the max capacity of the cache.\nSets the max capacity of the cache.\nName for this cache instance.\nname node of this backend\nThe namespace for surrealdb.\nThe namespace ID. Used as URI path parameter.\nSets the segments number of the cache.\nSet oidc_provider_arn for this backend.\n<code>oidc_provider_arn</code> will be loaded from\nSet oidc_token_file for this backend.\n<code>oidc_token_file</code> will be loaded from\nusername of this backend.\nGitHub repo owner.\nparent_resource_id of this backend\nset password for http backend\nthe password for authentication\npassword of this backend\npassword of this backend\npassword of this backend.\npassword of this backend. (Must be the application …\nPassword for Lakefs basic authentication.\nMemcached password, optional.\nThe password of nebulagraph’s graphd server\npCloud password.\nthe password for authentication\npassword of this backend.\nThe password for surrealdb.\npassword of this backend.\npassword of this backend\nThe host port of nebulagraph’s graphd server\nSet the predefined acl for GCS.\nThe predefined acl for GCS.\nSet an endpoint for generating presigned urls.\nPresign endpoint for oss.\nprivate_key of this backend\npublic_key of this backend\nThe refresh_token of this backend.\nrefresh_token for dropbox.\nRefresh token for gdrive.\nRegion represent the signing region of this endpoint. This …\nRegion represent the signing region of this endpoint. This …\nGitHub repo name.\nRepo id of this backend.\nrepo_name of this backend.\nRepo type of this backend. Default is model.\nThe repository name\nRevision of this backend.\nSet role_arn for this backend.\nSet role_arn for this backend.\nIf <code>role_arn</code> is set, we will use already known config as …\nrole_arn for this backend.\nSet role_session_name for this backend.\nSet role_session_name for this backend.\nrole_session_name for this backend.\nrole_session_name for this backend.\nSet root of this backend.\nSet root for backend.\nset the working directory root of backend\nSet root path of http backend.\nSet the root for BTreeMap.\nSet root of this backend.\nSet root of this backend.\nThe Root of this backend.\nroot of this backend.\nwork dir of this backend\nThe root of Azblob service backend.\nRoot of this backend.\nThe root path for azfile.\nroot of this backend.\nroot of this backend.\nRoot within this backend.\nroot of this backend.\nRoot of this backend.\nSet the working directory of OpenDAL.\nThe root path for dashmap.\nThe root for dbfs.\nroot path for dropbox.\nthe working directory of the etcd service. Can be “…\nroot of the backend.\nroot dir for backend\nroot of this backend\nroot URI, all operations happens under <code>root</code>\nThe root for gdrive\nThe root path for ghac.\nroot of this backend.\nThe working directory, all operations will be performed …\nwork dir of this backend\nwork dir of this backend\nroot of this backend\nRoot of this backend. Can be “/path/to/dir”.\nroot of this backend.\nIPFS root.\nRoot for ipfs.\nroot of this backend.\nRoot of this backend. Can be “/path/to/dir”.\nthe working directory of the service. Can be “…\nroot of the backend.\nroot path of this backend\nroot path of this backend\nroot of this backend\nThe Root of this backend.\nThe root for mysql.\nThe root for NebulaGraph\nRoot for obs.\nroot path of OneDrive folder.\nRoot for oss.\nroot of this backend.\nRoot of this backend.\nThe root for redb.\nthe working directory of the Redis service. Can be “…\nthe working directory of the service. Can be “…\nroot of this backend.\nroot of this backend.\nroot of this backend\nThe root for sled.\nset the working directory, all operations will be …\nThe root for supabase service.\nThe root for surrealdb.\nThe root for Swift.\nroot of this backend.\nroot of this backend.\nroot of this backend\nRoot for webhdfs.\nroot of this backend.\nThe runtime token for ghac service.\nSet sas_token of this backend.\nThe sas token of Azblob service backend.\nThe sas token for azfile.\nset the GCS service scope\nScope for gcs.\nSet secret_access_key of this backend.\nSecret access key for obs.\nsecret_access_key of this backend.\nSecret ID of this backend.\nSecret key of this backend.\nSet temporary credential used in AWS S3 connections\nThat name of the persy segment.\nSet server_side_encryption for this backend.\nSet server_side_encryption for this backend.\nServer side encryption for oss.\nserver_side_encryption for this backend.\nSet server_side_encryption_aws_kms_key_id for this backend\nserver_side_encryption_aws_kms_key_id for this backend\nSet server_side_encryption_customer_algorithm for this …\nserver_side_encryption_customer_algorithm for this backend.\nSet server_side_encryption_customer_key for this backend.\nserver_side_encryption_customer_key for this backend.\nSet server_side_encryption_customer_key_md5 for this …\nSet server_side_encryption_customer_key_md5 for this …\nSet server_side_encryption_key_id for this backend.\nServer side encryption key id for oss.\nEnable server side encryption with aws managed kms key\nEnable server side encryption with customer key.\nEnable server side encryption with customer key.\nEnable server side encryption with customer managed kms key\nEnable server side encryption with s3 managed key\nSet the GCS service account.\nService Account for gcs.\nSet temporary credential used in AWS S3 connections\nsession_token (aka, security token) of this backend.\nThe share name for azfile.\nThe space name of nebulagraph’s graphd server\nSet sts_endpoint for this backend.\n<code>sts_endpoint</code> will be loaded from\nSet the table of D1 Database.\nThe table name for mysql.\nthe table of postgresql\nThe table name for redb.\nSet the table name of the sqlite service to read/write.\nThe table for surrealdb.\nThe tag name of nebulagraph’s graphd server\nSets the time to idle of the cache.\nSets the time to idle of the cache.\nSets the time to live of the cache.\nSets the time to live of the cache.\nProvide the OAuth2 token to use.\nset bearer token for http backend\nThe token used to authenticate with CloudFlare.\nSet the token of cloudflare api.\nThe token for dbfs.\nA Google Cloud OAuth2 token.\nGitHub access_token.\ntoken of this backend\nToken of this backend.\nThe token for Swift.\nvercel blob token.\ntoken of this backend\nThe tree for sled.\nSession\nurl of this backend\nuser of this backend\nuser of this backend\nuser of this backend\nName of the user for webhdfs.\nset username for http backend\nthe username to connect etcd service.\nusername of this backend\nUsername for Lakefs basic authentication.\nMemcached username, optional.\nThe username of nebulagraph’s graphd server\npCloud username.\nthe username to connect redis service.\nusername of this backend.\nThe username for surrealdb.\nusername of this backend\nSet the value field of D1 Database.\nvalue field of this backend\nThe value field name for mysql.\nThe value field name of the NebulaGraph service to …\nthe value field of postgresql\nSet the value field name of the sqlite service to …\nThe value field for surrealdb.\nThe version that used by cache.\nTemp folder for object store test\nTest s3 config from environment variables\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nReturns s3 test config, return None if not found.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nJoin two paths and normalize the output dir.\nPush <code>child</code> to <code>parent</code> dir and normalize the output path.\nModified from the <code>opendal::raw::normalize_root</code>\nMake sure all operation are constructed by normalized path:\nAttaches instrument layers to the object store.")